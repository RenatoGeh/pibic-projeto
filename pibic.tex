\documentclass[12pt]{article}

\usepackage[brazilian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{thmtools,thm-restate}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage[singlelinecheck=false]{caption}
\usepackage[backend=biber,url=true,doi=true,eprint=false,style=alphabetic]{biblatex}
\usepackage{enumitem}
\usepackage[justification=centering]{caption}
\usepackage{indentfirst}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{listings}
\usepackage[x11names, rgb]{xcolor}
\usepackage{tikz}
\usepackage{hyperref}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{linegoal}
\usetikzlibrary{snakes,arrows,shapes}

\addbibresource{references.bib}
\graphicspath{{imgs/}}

\makeatletter
\def\subsection{\@startsection{subsection}{3}%
  \z@{.5\linespacing\@plus.7\linespacing}{.1\linespacing}%
  {\normalfont}}
\makeatother

\makeatletter
\patchcmd{\@setauthors}{\MakeUppercase}{}{}{}
\makeatother

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\Val}{\text{Val}}
\DeclareMathOperator*{\Ch}{\text{Ch}}
\DeclareMathOperator*{\Pa}{\text{Pa}}
\DeclareMathOperator*{\Sc}{\text{Sc}}
\newcommand{\ov}{\overline}

\newcommand\defeq{\mathrel{\overset{\makebox[0pt]{\mbox{\normalfont\tiny\sffamily def}}}{=}}}

\newcommand{\algorithmautorefname}{Algorithm}
\algrenewcommand\algorithmicrequire{\textbf{Input}}
\algrenewcommand\algorithmicensure{\textbf{Output}}
\algnewcommand{\LineComment}[1]{\State\,\(\triangleright\) #1}

\captionsetup[table]{labelsep=space}

\theoremstyle{plain}

\newcounter{dummy-def}\numberwithin{dummy-def}{section}
\newtheorem{definition}[dummy-def]{Definition}
\newcounter{dummy-thm}\numberwithin{dummy-thm}{section}
\newtheorem{theorem}[dummy-thm]{Theorem}
\newcounter{dummy-prop}\numberwithin{dummy-prop}{section}
\newtheorem{proposition}[dummy-prop]{Proposition}
\newcounter{dummy-corollary}\numberwithin{dummy-corollary}{section}
\newtheorem{corollary}[dummy-corollary]{Corollary}
\newcounter{dummy-lemma}\numberwithin{dummy-lemma}{section}
\newtheorem{lemma}[dummy-lemma]{Lemma}
\newcounter{dummy-ex}\numberwithin{dummy-ex}{section}
\newtheorem{exercise}[dummy-ex]{Exercise}
\newcounter{dummy-eg}\numberwithin{dummy-eg}{section}
\newtheorem{example}[dummy-eg]{Example}

\numberwithin{equation}{section}

\newcommand{\set}[1]{\mathbf{#1}}
\newcommand{\pr}{\mathbb{P}}
\newcommand{\eps}{\varepsilon}
\renewcommand{\implies}{\Rightarrow}

\newcommand{\bigo}{\mathcal{O}}

\setlength{\parskip}{1em}

\lstset{frameround=fttt,
	numbers=left,
	breaklines=true,
	keywordstyle=\bfseries,
	basicstyle=\ttfamily,
}

\newcommand{\code}[1]{\lstinline[mathescape=true]{#1}}
\newcommand{\mcode}[1]{\lstinline[mathescape]!#1!}


\title{%
  \vspace{-2.5cm}
  {\includegraphics[scale=0.2]{logo-usp.png}}\\
  {\textbf{\uppercase{\Large USP --- Universidade de São Paulo}}}\\
  \vspace{2cm}
  {Aprendizagem paramétrica e estrutural de redes soma-produto}\\
  \vspace{2.5cm}
\flushleft{Candidato: Renato Lui Geh\\
Orientador: Prof.\ Dr.\ Denis Deratani Mauá}\\
  \vspace{2.5cm}
  \centering
  {\textbf{São Paulo}}\\
  \vspace{0.25cm}
  {\textbf{2017}}\\
  \clearpage
}
\date{}

\begin{document}

\maketitle

\section{Introdução}

Aprendizado de máquina é uma área da Inteligência Artificial cujo objetivo é estatísticamente
ajustar os parâmetros de um certo modelo matemático dado um conjunto de dados a fim de que seja
possível fazer previsões acuradas do que se está modelando. Para isso, faz-se uso de modelos
estatísticos que possibilitam, por meio de métodos computacionais, lidar com um grande número de
variáveis e fazer previsões com alta taxa de acerto. Por meio da Estatística, é possível resolver
um grande número de problemas cujo número de variáveis seria grande demais para humanos.  Modelos
probabilísticos baseados em grafos (PGM, do inglês Probabilistic Graphical Model), são uma classe
destes modelos estatísticos em que se usa grafos para representá-los graficamente.

Os modelos probabilísticos baseados em grafos representam uma distribuição de probabilidade de
forma compacta. Estes modelos representados por grafos facilitam tanto a compreensão humana ao
estudá-los, quanto possibilitam que vários problemas já existentes em Teoria dos Grafos sejam
utilizados como solução para problemas em PGMs. Extrair conhecimento de PGMs é análogo a extrair a
probabilidade de um certo evento ocorrer dado que eventos distintos tenham ocorrido. Tal extração
de conhecimento é chamada de inferência, e em modelos probabilísticos isto se dá por meio de
probabilidades. Fazer inferência exata em PGMs clássicas, ou seja, acharmos a probabilidade exata
de um certo evento, é intratável. Uma solução para este problema é utilizarmos métodos para
inferência aproximada em tais modelos. No entanto, tais algoritmos aproximados são muitas vezes
difíceis de analisar e 


\printbibliography[]

\end{document}
