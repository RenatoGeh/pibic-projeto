\documentclass[12pt]{article}

\usepackage[brazilian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{thmtools,thm-restate}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage[singlelinecheck=false]{caption}
\usepackage[backend=biber,url=true,doi=true,eprint=false,style=numeric]{biblatex}
\usepackage{enumitem}
\usepackage[justification=centering]{caption}
\usepackage{indentfirst}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{listings}
\usepackage[x11names,rgb,table]{xcolor}
\usepackage{tikz}
\usepackage{hyperref}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{linegoal}
\usepackage{geometry}
\usetikzlibrary{snakes,arrows,shapes}

\addbibresource{references.bib}
\graphicspath{{imgs/}}

\makeatletter
\def\subsection{\@startsection{subsection}{3}%
  \z@{.5\linespacing\@plus.7\linespacing}{.1\linespacing}%
  {\normalfont}}
\makeatother

\makeatletter
\patchcmd{\@setauthors}{\MakeUppercase}{}{}{}
\makeatother

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\Val}{\text{Val}}
\DeclareMathOperator*{\Ch}{\text{Ch}}
\DeclareMathOperator*{\Pa}{\text{Pa}}
\DeclareMathOperator*{\Sc}{\text{Sc}}
\newcommand{\ov}{\overline}
\newcommand{\tsup}{\textsuperscript}

\newcommand\defeq{\mathrel{\overset{\makebox[0pt]{\mbox{\normalfont\tiny\sffamily def}}}{=}}}

\newcommand{\algorithmautorefname}{Algorithm}
\algrenewcommand\algorithmicrequire{\textbf{Input}}
\algrenewcommand\algorithmicensure{\textbf{Output}}
\algnewcommand{\LineComment}[1]{\State\,\(\triangleright\) #1}

\captionsetup[table]{labelsep=space}

\theoremstyle{plain}

\newcounter{dummy-def}\numberwithin{dummy-def}{section}
\newtheorem{definition}[dummy-def]{Definition}
\newcounter{dummy-thm}\numberwithin{dummy-thm}{section}
\newtheorem{theorem}[dummy-thm]{Theorem}
\newcounter{dummy-prop}\numberwithin{dummy-prop}{section}
\newtheorem{proposition}[dummy-prop]{Proposition}
\newcounter{dummy-corollary}\numberwithin{dummy-corollary}{section}
\newtheorem{corollary}[dummy-corollary]{Corollary}
\newcounter{dummy-lemma}\numberwithin{dummy-lemma}{section}
\newtheorem{lemma}[dummy-lemma]{Lemma}
\newcounter{dummy-ex}\numberwithin{dummy-ex}{section}
\newtheorem{exercise}[dummy-ex]{Exercise}
\newcounter{dummy-eg}\numberwithin{dummy-eg}{section}
\newtheorem{example}[dummy-eg]{Example}

\numberwithin{equation}{section}

\newcommand{\set}[1]{\mathbf{#1}}
\newcommand{\pr}{\mathbb{P}}
\newcommand{\eps}{\varepsilon}
\renewcommand{\implies}{\Rightarrow}

\newcommand{\bigo}{\mathcal{O}}

\setlength{\parskip}{1em}

\lstset{frameround=fttt,
	numbers=left,
	breaklines=true,
	keywordstyle=\bfseries,
	basicstyle=\ttfamily,
}

\newcommand{\code}[1]{\lstinline[mathescape=true]{#1}}
\newcommand{\mcode}[1]{\lstinline[mathescape]!#1!}


\title{%
  \vspace{-2.5cm}
  {\includegraphics[scale=0.2]{logo-usp.png}}\\
  {\textbf{\uppercase{\Large USP --- Universidade de São Paulo}}}\\
  \vspace{2cm}
  {Aprendizagem paramétrica e estrutural de redes soma-produto}\\
  \vspace{2.5cm}
\flushleft{Candidato: Renato Lui Geh\\
Orientador: Prof.\ Dr.\ Denis Deratani Mauá}\\
  \vspace{2.5cm}
  \centering
  {\textbf{São Paulo}}\\
  \vspace{0.25cm}
  {\textbf{2017}}\\
}
\date{}

\begin{document}

\maketitle

\newgeometry{margin=1in}
\section{Introdução}

Aprendizado de máquina é uma área da Inteligência Artificial cujo objetivo é estatisticamente
ajustar os parâmetros de um certo modelo matemático dado um conjunto de dados a fim de que seja
possível fazer previsões acuradas do que se está modelando. Para isso, faz-se uso de modelos
estatísticos que possibilitam, por meio de métodos computacionais, lidar com um grande número de
variáveis e fazer previsões com alta taxa de acerto. Por meio da Estatística e Computação, é
possível resolver um grande número de problemas cujo número de variáveis seria grande demais para
humanos.  Modelos probabilísticos baseados em grafos (PGM, do inglês \textit{Probabilistic
Graphical Model}), são uma classe destes modelos estatísticos em que se usa grafos para
representá-los graficamente.

Os modelos probabilísticos baseados em grafos representam uma distribuição de probabilidade de
forma compacta. Estes modelos representados por grafos facilitam tanto a compreensão humana ao
estudá-los, quanto possibilitam que vários problemas já existentes em Teoria dos Grafos sejam
utilizados como solução para problemas em PGMs. Extrair conhecimento de PGMs é análogo a extrair a
probabilidade de um certo evento ocorrer dado que eventos distintos tenham ocorrido. Tal extração
de conhecimento é chamada de inferência. Fazer inferência exata em PGMs clássicas, ou seja,
acharmos a probabilidade exata de um certo evento, é intratável. Uma solução para este problema é
utilizarmos métodos para inferência aproximada em tais modelos. No entanto, tais algoritmos
aproximados são muitas vezes difíceis de analisar. Além disso, como os algoritmos de aprendizado do
modelo utilizam inferência como subrotina, por consequência o aprendizado torna-se aproximado.

Redes soma-produto (SPN, de \textit{Sum-Product Network}) são PGMs que representam uma distribuição
de probabilidade tratável. Proposto em 2011, SPNs computam inferência exata em tempo linear ao
número de arestas de seu grafo se obedecerem a certas propriedades~\cite{poon-domingos}. SPNs
apresentam uma série de características interessantes, como sua arquitetura profunda que permite
representar funções de forma mais eficiente quanto mais profundo seu grafo~\cite{shallow-vs-deep}.
Outras interessantes propriedades teóricas incluem uma generalização de SPNs para qualquer
semi-anel em que o produto tenha escopo disjunto~\cite{sp-theorem}. SPNs tiveram resultados
impressionantes em diversas aplicações, como enovelamento de proteínas~\cite{rec-dec-non-convex},
modelagem de sinais~\cite{model-speech}, classificação e reconstrução de imagens
\cite{gens-domingos,poon-domingos,clustering}, reconhecimento de atividade~\cite{activity} e
linguagem natural~\cite{nat-lang}.

Neste projeto, pretende-se desenvolver uma biblioteca livre e gratuita para algoritmos de
aprendizado estado-da-arte e inferência em SPNs, analisando-se experimentalmente tais algoritmos em
tarefas reais, como compleição e classificação de imagens.
\newpage

\section{Objetivos}

Os objetivos esperados neste trabalho são:

\begin{enumerate}
  \item Domínio de conceitos sobre aprendizagem de SPNs.
  \item Desenvolvimento de uma biblioteca livre e gratuita de algoritmos de aprendizado de SPNs
    estado-da-arte.
  \item Análise experimental comparativa em tarefas reais.
\end{enumerate}

\section{Metodologia}

A pesquisa terá seu início com o estudo dos conceitos e do estado-da-arte de SPNs, estudando-se
diferentes métodos de aprendizagem de SPNs, tanto estruturais quanto relativos aos pesos do grafo.

Após o entendimento de cada algoritmo de aprendizagem, será iniciada a implementação do algoritmo
na biblioteca livre e gratuita a ser desenvolvida, buscando documentar o código e elaborar
relatórios. Com o desenvolvimento dos diferentes algoritmos de aprendizagem, pretende-se elaborar
relatórios contendo uma comparação experimental em conjuntos de dados reais.

Durante a realização do projeto, serão elaborados documentos científicos para possível submissão a
ENIAC 2017 e para o acompanhamento geral do desempenho acadêmico do candidato.

O cronograma para o desenvolvimento desta pesquisa segue abaixo.


\begin{table}[h]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Atividade/Mês & 1\tsup{o}--2\tsup{o} & 4\tsup{o}--5\tsup{o} & 6\tsup{o}--7\tsup{o} &
    8\tsup{o}--10\tsup{o} & 11\tsup{o}--12\tsup{o} \\ \hline
    a & $\times$ & & & & \\ \hline
    b & & & & & \\ \hline
    c & & & & & \\ \hline
    d & & & & & \\ \hline
    e & & & & & \\
    \hline
  \end{tabular}
\end{table}

%\begin{enumerate}[label=\alpha*]
  %\item a
  %\item b
  %\item c
%\end{enumerate}

\printbibliography[]

\end{document}
